
# Welcome to Dawei Li's Homepage!
<!-- 注释掉该句# Welcome to Dawei Li's Personal Homepage! -->


<table border="0">
  <tr>
    <td width="100%">
      <h2>Dawei Li 李大威</h2>
      <p><b>PhD, Associate Professor</b></p>
      <p><b>Dean of Automation Department</b></p>
      <p><b>I am with the College of Information Sciences and Technology, the Engineering Research Center of Digitized Textile & Fashion Technology of Ministry of Education, and with the State Key Laboratory for Modification of Chemical Fibers and Polymer Materials (SKLFPM)</b></p>
      <p><b>Donghua University (211, Double First-Class)</b></p>
      <p><b>2999 North Renmin Rd., Songjiang District, Shanghai, China 201620</b></p>
      <p><b>Email: daweili[A.T.]dhu.edu.cn</b></p>
    </td>
  </tr>
</table>

## Academic History and Education Background:
<p>I received B.E. in Automation in 2006 from Tongji University, Shanghai, China. During 2009-2010, I was a visiting researcher at Michigan State University, East Lansing, MI, USA. In 2013, I received the Ph.D. in Control Theory and Control Engineering from Tongji University, Shanghai, China. During 2013-2015, I was a postdoc at the Department of Computer Sciences and Technology, Tongji University, Shanghai, China. Currently an associate professor with Donghua University, Songjiang District, Shanghai, China. </p>

<!-- 注释掉该句 <p>➤ <a href=""><strong></strong></a></p>  -->

## Research Interests:
<p>Image Processing, Point Cloud Processing, Artificial Intelligence, Intelligent Visual Surveillance, and Plant Phenotyping.</p>

## Teaching:
<p><i>Semester A (Autumn): </i></p>
<p>1.	Data Analysis and Machine Learning (for graduate students). </p>
<p>2.	Pattern Recognition Principles and Techniques (for international student/joint course with Dr. Huang).</p>
<p>3.	Frontiers of AI (for undergraduates).</p>
<p>4.	Professional Introduction (for undergraduates).</p>
<p><i>Semester B (Spring): </i></p>
<p>1.	Machine Learning (for undergraduates).</p>
<p>2.	Production Practice for AI (for undergraduates/joint course with Dr. Pan).</p>

## Research Projects and Talent Programs:
<p>1.	Donghua University 2025 Cultivation Project of Discipline Innovation (xkcx-202505), Person in Charge. (07/2025-06/2028).</p>
<p>2.	Shanghai Rising-Star Program, Person in Charge. (07/2021-06/2024).</p>
<p>3.	“Research on the stereo imaging for plant phenotyping and genotype analysis”, Natural Science Foundation of Shanghai, Person in Charge. (07/2020-06/2023).</p>
<p>4.	“3D imaging for analyzing the phenotypes of textile plants”, The Fundamental Research Funds for the Central Universities of China (special base project), Person in Charge. (01/2019-04/2020)</p>
<p>5.	“Research of illumination-robust stereo vision algorithm for greenhouse plants”, National Natural Science Foundation of China, Person in Charge. (01/2017-12/2019).</p>
<p>6.	Shanghai Sailing Program, Person in Charge. (06/2016-05/2019).</p>
<p>7.	“Research on illumination-robust stereo vision imaging tools for greenhouse plants”, The Fundamental Research Funds for the Central Universities of China, Person in Charge. (01/2016-12/2018)</p>
<p>8.	“A research on digitization and virtual visualization of greenhouse tomato plants”, China Postdoctoral Science Foundation Special Grants, Person in Charge. (07/2014-07/2015).</p>
<p>9.	“Research on key technology in an intelligent video surveillance system”, Shanghai Yangpu District Innovation and Practice base project for postdocs, Person in Charge. (02/2014-12/2014).</p>
<p>10.	“The research of digitized imaging and virtual visualization technologies on greenhouse plants”, China Postdoctoral Science Foundation 1st class grants, Person in Charge. (07/2013-12/2014).</p>

## Academic Participation:
<p>1.	Chinese Society of Agricultural Engineering, Senior Member.</p>
<p>2.	Chinese Association of Automation, Member.</p>
<p>3.	Shanghai Agricultural Engineering Association, Standing Director.</p>
<p>4.	IEEE, Member.</p>
<p>5.	IEEE CIS Shanghai Chapter, Secretary General.</p>
<p>6.	Reviewer for a number of international conferences and journals including <i>IEEE SPL, IEEE TCSVT, IEEE TMM, IEEE TCYB, IEEE ACCESS, IEEE RA-L, Graphics & Visual Computing, Plant Phenomics, Integrated Computer-Aided Engineering, Neurocomputing, IJPRAI, Applied Engineering in Agriculture (ASABE), Ecological Informatics, The Visual Computer, Automation in Construction, China Communications, International Journal of Remote Sensing, Scientific Programming, Frontiers in Plant Science, and NCAA.</i></p>

## Honors and Awards:
<p>1.	Best Paper Award for Young Researchers at The Annual Academic Conference of Chinese Society of Agricultural Engineering (3/4), Zhenjiang, China. (08/2013)</p>
<p>2.	Best Doctoral Dissertation Award of Year 2013 (Top 28 among 592, 1/1), Tongji University, Shanghai, China. (05/2013)</p>
<p>3.	Finalist for Best Paper Award (Top 6 among 899, 1/3) in the 11th International Conference on Control, Automation, Robotics and Vision (ICARCV2010), Singapore. (12/2010)</p>

## Selected Publications:

<p>[1] <b>D. Li</b>†, J. Huang†, B. Zhao, and W. Wen*, “Organ3DNet: a deep network for segmenting organ semantics and instances from dense plant point clouds,” <font color="#5B00AE"><i>Artificial Intelligence in Agriculture</i></font>, Vol. 16, No. 1, March 2026, pp. 342-364. (†Contributed equally).</p>

[[Paper](https://www.sciencedirect.com/science/article/pii/S2589721725000911)]

[[Code](https://github.com/Huang2002200/Organ3DNet)]

<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="Organ3DNet-1.jpg" width="85%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="Organ3DNet-2.jpg" width="85%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="Organ3DNet-3.jpg" width="85%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>


<p>[2] <b>D. Li</b>†, T. Li†, S. Xu, and S. Jin*, “AR-plant: AR-based semi-automatic labeling system for 3D plant organs,” <font color="#5B00AE"><i>ISPRS Journal of Photogrammetry and Remote Sensing</i></font>, Vol. 230, pp. 843-860, 2025. (†Contributed equally).</p>

[[Paper](https://www.sciencedirect.com/science/article/abs/pii/S0924271625003922)]

[[8-minute presentation](https://www.bilibili.com/video/BV1BgsRzhEQj)]

[[Code](https://github.com/yehaaaa/AR-PLANT)]

<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="AR-PLANT1.gif" width="85%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="AR-PLANT2.jpg" width="85%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="AR-PLANT3.gif" width="85%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[3] S. Jin†, <b>D. Li</b>†, T. Yun†, J. Tang, K. Wang, S. Li, ..., and Y. Ding, “Deep learning for three-dimensional (3D) plant phenomics,” <font color="#5B00AE"><i>Plant Phenomics</i></font>, Vol. 7, 100107, 2025. (Review Paper) (†Contributed equally).</p>

[[Review Paper](https://www.sciencedirect.com/science/article/pii/S264365152500113X)]

<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="Review2025-1.jpg" width="85%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[4] <b>D. Li</b>†, F. Ahmed†, and Z. Wang†, “3D-NOD:  3D New Organ Detection in Plant Growth by a Spatiotemporal Point Cloud Deep Segmentation Framework,” <font color="#5B00AE"><i>Plant Phenomics</i></font>, 2025, Vol. 7, No. 1, 100002. (†Contributed equally).</p>

[[Paper](https://www.sciencedirect.com/science/article/pii/S2643651525000081)]

[[11-minute presentation](https://www.bilibili.com/video/BV1HGktYoEwP/)]

[[Code](https://github.com/zingersu/3D-New-Organ-Detection-in-Plant-Growth-from-Spatiotemporal-Point-Clouds)]

<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="3D-NOD1.gif" width="85%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="3D-NOD2.jpg" width="85%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="3D-NOD3.jpg" width="85%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<p>[5] <b>D. Li</b>†, L. Liu†, S. Xu, and S. Jin*, “TrackPlant3D: 3D organ growth tracking framework for organ-level dynamic phenotyping,” <font color="#5B00AE"><i>Computers and Electronics in Agriculture</i></font>, Vol. 226, 2024, 109435. (†Contributed equally).</p>

[[Paper](https://www.sciencedirect.com/science/article/abs/pii/S0168169924008263)]

[[12-minute presentation](https://www.bilibili.com/video/BV1mKYSeZErt)]

[[Code](https://github.com/entarot/TrackPlant3D-3D-organ-growth-tracking-framework-for-organ-level-dynamic-phenotyping )]

<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="TrackPlant3D2.jpg" width="65%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="TrackPlant3D1.jpg" width="85%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[6] <b>D. Li</b>†, Z. Zhou†, and Y. Wei, “Unsupervised shape-aware SOM down-sampling for plant point clouds,” <font color="#5B00AE"><i>ISPRS Journal of Photogrammetry and Remote Sensing</i></font>, vol. 211, 2024, pp. 172-207. (†Contributed equally)</p>

[[Paper](https://doi.org/10.1016/j.isprsjprs.2024.03.024)]

[[10-minute presentation](https://www.bilibili.com/video/BV1LTg4enEM5/)]

[[Code](https://github.com/chinazhouzhaoyi/SOM-down-sampling-for-plant-point-clouds/)]

<table border="0">
  <tr>
     <td width="70%" align="right">
      <img src="SOM展示图1a.jpg" width="84%" /> 
    </td>
    <td width="30%">
      <img src="SOM迭代.gif" width="100%" /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="SOM展示图1b.jpg" width="85%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="SOM展示图2.jpg" width="60%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="SOM展示图3.jpg" width="98%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[7] <b>D. Li</b>, Y. Wei, and R. Zhu, “A comparative study on point cloud down-sampling strategies for deep learning-based crop organ segmentation,” <font color="#5B00AE"><i>Plant Methods</i></font>, vol. 19, Article No. 124, 2023. </p>

[[Paper](https://link.springer.com/article/10.1186/s13007-023-01099-7/)]

[[Code](https://github.com/WeiyongchangChina/A-comparative-study-on-point-cloud-down-sampling-strategies-for-deep-learning-based-crop-organ-seg/)]

<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="降采样展示图1.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="降采样展示图2.jpg" width="54%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[8] <b>D. Li</b>, J. Li, S. Xiang, and A. Pan, “PSegNet: simultaneous semantic and instance segmentation for point clouds of plants,” <font color="#5B00AE"><i>Plant Phenomics</i></font>, 2022, Article ID: 9787643.</p>

[[Paper](https://spj.science.org/doi/10.34133/2022/9787643)]

[[10-minute presentation](https://www.bilibili.com/video/BV1EEaTedE4a/)]

[[Code](https://github.com/Huang2002200/PlantNet-and-PSegNet/)]

<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="PSegNet展示图1.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="PSegNet展示图2.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="PSegNet展示图3.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<!-- 注释掉该部分
<table border="0">
  <tr>
     <td width="55%">
      <img src="PSegNet展示图2.jpg" width="100%" /> 
    </td>
    <td width="45%">
      <img src="PSegNet展示图3.jpg" width="100%" /> 
    </td>
  </tr>
</table>
-->

<p>[9] <b>D. Li</b>†, F. Ahmed†, N. Wu, and A. I. Sethi, “YOLO-JD: A Deep Learning Network for Jute Diseases and Pests Detection from Images,” <font color="#5B00AE"><i>Plants</i></font>, vol. 11, no. 7: 937, 2022. (†Contributed equally)</p>

[[Code](https://github.com/foysalahmed10/YOLO-JD)]

<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="Jute展示图1.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="Jute展示图2.jpg" width="60%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[10] <b>D. Li</b>†, S. Wang†, S. Xiang, J. Li, Y. Yang, and X.-S. Tang, “Dual-stream shadow detection network – biologically inspired shadow detection for remote sensing images,” <font color="#5B00AE"><i>Neural Computing and Applications</i></font>, vol. 34, 10039-10049, 2022. (†Contributed equally)</p>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="DSSDN展示图1.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="DSSDN展示图2.jpg" width="75%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[11] <b>D. Li</b>†, G. Shi†, J. Li, Y. Chen, S. Zhang, S. Xiang, and S. Jin, “PlantNet: A dual-function point cloud segmentation network for multiple plant species”,  <font color="#5B00AE"><i>ISPRS Journal of Photogrammetry and Remote Sensing</i></font>, vol. 184, 2022, pp. 243-263. (†Contributed equally)</p>

[[Paper](https://www.sciencedirect.com/science/article/abs/pii/S0924271622000119)]

[[Code](https://github.com/Huang2002200/PlantNet-and-PSegNet/)]

<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="PlantNet展示图1.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
     <td width="50%">
      <img src="PlantNet展示图2.jpg" width="100%" /> 
    </td>
    <td width="50%">
      <img src="PlantNet展示图3.jpg" width="100%" /> 
    </td>
  </tr>
</table>

<p>[12] X.-S. Tang, X. Xie, K. Hao, <b>D. Li</b>*, and M. Zhao, “A line-segment-based non-maximum suppression method for accurate object detection,”  <font color="#5B00AE"><i>Knowledge-Based Systems</i></font>, vol. 251, no. 5, 2022, 108885.</p>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="KBS展示图1.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="KBS展示图2.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[13] <b>D. Li</b>, G. Shi, Y. Wu, Y. Yang, and M. Zhao, “Multi-scale neighborhood feature extraction and aggregation for point cloud segmentation”, <font color="#5B00AE"><i>IEEE Transactions on Circuits and Systems for Video Technology</i></font>, vol. 31, no. 6, 2021, pp. 2175-2191.</p>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="MNFEAM展示图1.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="MNFEAM展示图2.gif" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="MNFEAM展示图3.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[14] <b>D. Li</b>, S. Yan, M. Zhao, and T.W.S. Chow, “Spatiotemporal Tree Filtering for Enhancing Image Change Detection”, <font color="#5B00AE"><i>IEEE Transactions on Image Processing</i></font>, vol. 29, pp. 8805-8820, 2020.</p>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="FSTF展示图1.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="FSTF展示图2.jpg" width="100%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="FSTF展示图3.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[15] <b>D. Li</b>, S. Wang, X.-S. Tang, W. Kong, G. Shi, and Y. Chen, “Double-stream Atrous Network for Shadow Detection,” <font color="#5B00AE"><i>Neurocomputing</i></font>, vol. 317, 2020, pp. 167-175.</p>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="DSAN展示图1.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="DSAN展示图2.jpg" width="95%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="DSAN展示图3.gif" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="DSAN展示图4.gif" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[16] <b>D. Li</b>, G. Shi, W. Kong, S. Wang, and Y. Chen, “A leaf segmentation and phenotypic feature extraction framework for Multi-View Stereo plant point clouds,” <font color="#5B00AE"><i>IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing</i></font>, vol. 13, 2020, pp. 2321-2336.</p>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="JSTARS展示图1.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="JSTARS展示图2.gif" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="JSTARS展示图3.jpg" width="80%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[17] <b>D. Li</b>, Y. Cao, G. Shi, X. Cai, Y. Chen, S. Wang, and S. Yan, “An overlapping-free leaf segmentation method for plant point clouds,” <font color="#5B00AE"><i>IEEE Access</i></font>, vol. 7, no. 9, pp. 129054-129070, 2019.</p>

[[A 6-minute presentation](https://www.bilibili.com/video/BV11JveeDEeF/)]

[[Paper](https://ieeexplore.ieee.org/abstract/document/8830350)]

<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="O-f展示图1.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="O-f展示图2.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="O-f展示图3.gif" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[18] <b>D. Li</b>, S. Yan, X. Cai, Y. Cao, and S. Wang, “An Integrated image filter for enhancing change detection results,” <font color="#5B00AE"><i>IEEE Access</i></font>, vol. 7, no. 1, pp. 91034-91051, 2019.</p>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="IF展示图1.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="IF展示图2.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[19] <b>D. Li</b>, Y. Cao, X.-S. Tang, S. Yan, and X. Cai, “Leaf Segmentation on Dense Plant Point Clouds with Facet Region Growing,” <font color="#5B00AE"><i>Sensors</i></font>, vol. 18, no. 11, Article 3625, 2018.</p>

[[3-minute presentation](https://www.bilibili.com/video/BV1qyv4enExL)]

[[Paper](https://www.mdpi.com/356514)]

<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="FACETS展示图1.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="FACETS展示图2.gif" width="60%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[20] <b>D. Li</b>, L. Xu, X. Tang, S. Sun, X. Cai, and P. Zhang, “3D Imaging of Greenhouse Plants with an Inexpensive Binocular Stereo Vision System,” <font color="#5B00AE"><i>Remote Sensing</i></font>, vol. 9, no. 5, Article 508, 2017.</p>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="RS展示图1.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="RS展示图2.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="RS展示图3.gif" width="60%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[21] <b>D. Li</b>, L. Xu, and H. Liu, “Detection of Uneaten Fish Food Pellets in Underwater Images for Aquaculture,” <font color="#5B00AE"><i>Aquacultural Engineering</i></font>, vol. 78, Part B, pp. 85-94, 2017.</p>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="AQUA展示图1.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="AQUA展示图2.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[22] Y. Su, L. Xu, and <b>D. Li</b>, “Adaptive Fuzzy Control of a Class of MIMO Nonlinear System with Actuator Saturation for Greenhouse Climate Control Problem,” <font color="#5B00AE"><i>IEEE Transactions on Automation Science and Engineering</i></font>, vol. 13, no. 2, 2016, pp. 772-788.</p>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="TASE展示图1.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="TASE展示图2.jpg" width="80%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[23] <b>D. Li</b>, L. Xu, C. Tan, E.D. Goodman, D. Fu, and L. Xin, “Digitization and Visualization of Greenhouse Tomato Plants in Indoor Environments,” <font color="#5B00AE"><i>Sensors</i></font>, vol. 15, no. 2, 2015, pp. 4019-4051.</p>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="DV展示图1.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[24] <b>D. Li</b>, L. Xu, and E. Goodman, “On-line EM Variants for Multivariate Normal Mixture Model in Background Learning and Moving Foreground Detection,” <font color="#5B00AE"><i>Journal of Mathematical Imaging and Vision</i></font>, vol. 48, no. 1, 2014, pp. 114-133.</p>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="JMIV展示图1.jpg" width="70%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="JMIV展示图2.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="JMIV展示图3.gif" width="70%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[25] <b>D. Li</b>, L. Xu, and E. Goodman, “Illumination-robust Foreground Detection in a Video Surveillance System,” <font color="#5B00AE"><i>IEEE Transactions on Circuits and Systems for Video Technology</i></font>, vol. 23, no. 10, pp. 1637-1650, 2013.</p>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="SPK展示图1.jpg" width="90%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="SPK展示图2.gif" width="80%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[26] <b>D. Li</b>, L. Xu, E. Goodman, Y. Xu, and W. Yang, “Integrating a statistical background-foreground extraction algorithm and SVM classifier for pedestrian detection and tracking”, <font color="#5B00AE"><i>Integrated Computer-Aided Engineering</i></font>, vol. 20, no.3, 2013, pp. 201-216.</p>
<table border="0">
  <tr>
    <td width="100%" align="center">
      <img alt="" src="ICAE展示图1.jpg" width="80%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<p>[27] <b>D. Li</b>, L. Xu, and E. Goodman, “Online Background Learning for Illumination-robust Foreground Detection,” <font color="#5B00AE"><i>in: Proc. 11th International Conference on Control, Automation, Robotics and Vision (ICARCV)</i></font>, 2010, pp. 1093-1100. (<i>Finalist for Best Paper Award</i>)</p>
<table border="0">
  <tr>
    <td width="70%" align="center">
      <img alt="" src="ICARCV展示图1.jpg" width="100%" style="margin: 0 auto;"  /> 
    </td>
    <td width="30%" align="center">
      <img alt="" src="ICARCV展示图2.jpg" width="80%" style="margin: 0 auto;"  /> 
    </td>
  </tr>
</table>

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<p align="left"><b>The webpage has been visited <span id="busuanzi_value_site_pv"></span> times.</b></p>
<!-- 外层容器控制整体宽度和居中 -->
<div style="width: 60%; max-width: 600px; margin: 0 auto; text-align: center; position: relative;">
  <!-- 插件脚本，移除自身的width设置 -->
  <script 
    type="text/javascript" 
    id="clustrmaps" 
    src="https://clustrmaps.com/map_v2.js?d=jXbSyu9yHiqrIMG4S_wgh10OvbCo0cw11tLcV38Qv30&cl=ffffff&w=a"
    style="height: 400px; vertical-align: top; /* 消除inline元素默认垂直对齐空白,这句代码奇迹般地消除了垂直空白 */"
  ></script>
  
  <!-- 关键：添加CSS样式，直接控制插件生成的地图元素 -->
  <style>
    /* 针对ClustrMaps生成的iframe或div设置宽度 */
    #clustrmaps-container,
    #clustrmaps-container iframe,
    [id^="clustrmaps-widget"] {
      width: 100% !important; /* 继承父容器的60%宽度 */
      max-width: 100% !important;
      margin: 0 auto !important;
    }
  </style>
</div>



